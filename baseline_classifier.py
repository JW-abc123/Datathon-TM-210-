# -*- coding: utf-8 -*-
"""Baseline classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fcu3ZoC3n3nUBprP-F3LjsQiIgMLOkr7
"""

#Core libraries and model APIs
from pathlib import Path
import warnings

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import balanced_accuracy_score, f1_score, classification_report, roc_auc_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.utils.class_weight import compute_sample_weight

sns.set_theme(style="whitegrid", palette="deep")
pd.options.display.float_format = '{:,.2f}'.format

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_excel("CTG.xls", sheet_name=2,header=0,skiprows=[1],nrows=2126)
df = df.drop(columns=['FileName', 'Date', 'SegFile', 'CLASS', 'A', 'B', 'C', 'D', 'E', 'AD', 'DE', 'LD', 'FS', 'SUSP', 'LBE', 'b', 'e'])
df = df.drop_duplicates()

# Convert all columns to numeric, coercing errors to NaN
df = df.apply(pd.to_numeric, errors='coerce')

print("Columns:", df.columns)

target_col = "NSP"

X = df.drop(columns=[target_col])
y = df[target_col]

print(df)

print("\nMissing values per column:")
print(df.isnull().sum())

print("\nTarget distribution:")
print(y.value_counts(normalize=True))

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

print("Training set shape:", X_train.shape)
print("Test set shape:", X_test.shape)
print("\nTraining class distribution:")
print(y_train.value_counts())
print("\nTest class distribution:")
print(y_test.value_counts())

#shared evaluation helper(confusion matrix+f1_score,balanced accuracy+ROC AUC)

results = []

def evaluate_model(name, estimator, X_train, y_train, X_test, y_test, fit_kwargs=None, display_report=False):
    fit_kwargs = fit_kwargs or {}
    estimator.fit(X_train, y_train, **fit_kwargs)
    y_pred = estimator.predict(X_test)

    bal_acc = balanced_accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')

    # Calculate Macro ROC AUC
    # Need prediction probabilities for ROC AUC
    if hasattr(estimator, "predict_proba"):
        y_prob = estimator.predict_proba(X_test)
        try:
            # For multiclass, use average='macro'
            roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='macro')
        except ValueError as e:
            print(f"Could not calculate ROC AUC for {name}: {e}")
            roc_auc = np.nan # Assign NaN if calculation fails
    else:
        roc_auc = np.nan # Not applicable for models without predict_proba

    results.append({'Model': name, 'Balanced Accuracy': bal_acc, 'F1 Macro': f1, 'ROC AUC Macro': roc_auc})
    print(f"{name} — Balanced Accuracy: {bal_acc:.3f}, Macro F1: {f1:.3f}, Macro ROC AUC: {roc_auc:.3f}")

    if display_report:
        print(classification_report(y_test, y_pred, digits=3))

    disp = ConfusionMatrixDisplay.from_predictions(
        y_test, y_pred, display_labels=sorted(classes), normalize='true', cmap='Blues'
    )
    disp.ax_.set_title(f"{name} — Normalized Confusion Matrix")
    plt.show()
    return estimator, y_pred

sample_weight_train = compute_sample_weight(class_weight='balanced', y=y_train)
classes = np.unique(y_train)
classes

"""#Baseline Classifier"""

##logistic regression
log_reg_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('log_reg', LogisticRegression(
        max_iter=1000,
        multi_class='multinomial',
        class_weight='balanced',
        solver='lbfgs'
    ))
])
_ = evaluate_model('Logistic Regression', log_reg_pipeline, X_train, y_train, X_test, y_test, display_report=True)

##Decision Tree
tree_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('tree', DecisionTreeClassifier(
        criterion='gini',
        min_samples_leaf=5,
        max_depth=None,
        class_weight='balanced',
        random_state=42
    ))
])
_ = evaluate_model('Decision Tree', tree_pipeline, X_train, y_train, X_test, y_test)

##Random Forest
rf_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('rf', RandomForestClassifier(
        n_estimators=300,
        max_depth=None,
        min_samples_leaf=4,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    ))
])
_ = evaluate_model('Random Forest', rf_pipeline, X_train, y_train, X_test, y_test)

##Gradient Boosting
gb_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('gb', GradientBoostingClassifier(
        n_estimators=300,
        learning_rate=0.05,
        max_depth=3,
        random_state=42
    ))
])
gb_fit_kwargs = {'gb__sample_weight': sample_weight_train}
_ = evaluate_model('Gradient Boosting', gb_pipeline, X_train, y_train, X_test, y_test, fit_kwargs=gb_fit_kwargs)

##SVM
svm_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('svm', SVC(
        kernel='rbf',
        C=2.0,
        gamma='scale',
        class_weight='balanced'
    ))
])
_ = evaluate_model('Support Vector Machine', svm_pipeline, X_train, y_train, X_test, y_test)

##Nueral Network
mlp_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('mlp', MLPClassifier(
        hidden_layer_sizes=(64, 32),
        activation='relu',
        alpha=1e-3,
        learning_rate='adaptive',
        max_iter=1000,
        early_stopping=True,
        random_state=42
    ))
])
_ = evaluate_model('Neural Network (MLP)', mlp_pipeline, X_train, y_train, X_test, y_test)

#kNN
knn_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('knn', KNeighborsClassifier(n_neighbors=15))
])
_ = evaluate_model('k-Nearest Neighbors', knn_pipeline, X_train, y_train, X_test, y_test)

"""**Summary of Aggregate model performance**"""

results_df = pd.DataFrame(results).sort_values('Balanced Accuracy', ascending=False)
results_df.reset_index(drop=True)
results_df

fig, ax = plt.subplots(figsize=(10, 6)) # Increased figure size
results_df.plot(x='Model', y=['Balanced Accuracy', 'F1 Macro', 'ROC AUC Macro'], kind='bar', ax=ax) # Added ROC AUC
ax.set_ylim(0, 1)
ax.set_ylabel('Score')
ax.set_title('Model Comparison — Balanced Accuracy, Macro F1 & Macro ROC AUC') # Updated title
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""**Summary of models performance :** since Gradient Boosting having the best performance among the models and hence we decide to choose Random Forest for further fine tuning

: it is also good at classifying classes 1 and 3 and having low false negative rate.
"""