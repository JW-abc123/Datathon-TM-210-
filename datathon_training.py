# -*- coding: utf-8 -*-
"""datathon_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bO49GURxETJbVXhaMLWYSeXf7YWOJ40B

# **Data Import**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_excel("https://archive.ics.uci.edu/ml/machine-learning-databases/00193/CTG.xls", sheet_name="Data",header=1,nrows=2126)

df = df.dropna(axis=1, how='all')

print(df)

"""# **Data Cleaning**"""

#Drop the repeated (normalized) columns & leakage columns & duplicate rows
df = df.drop(columns=['AC.1', 'FM.1', 'UC.1', 'DL.1', 'DS.1', 'DP.1'], errors='ignore')
df = df.drop(columns=['CLASS', 'A', 'B', 'C', 'D', 'E', 'AD', 'DE', 'LD', 'FS', 'SUSP'], errors='ignore')
df = df.drop_duplicates()

# Convert all columns to numeric, coercing errors to NaN
df = df.apply(pd.to_numeric, errors='coerce')

#Map NSP column to 0 (Normal), 1 (Suspect), and 2 (Pathological)
df['NSP'] = df['NSP'] - 1

print("Columns:", df.columns)

print(df);

#Separate input columns and output column
target_col = "NSP"

X = df.drop(columns=[target_col])
y = df[target_col]

print("\nMissing values per column:")
print(df.isnull().sum())

print("\nTarget distribution:")
print(y.value_counts(normalize=True))

classes = ['Normal', 'Suspect', 'Pathologic']

"""# **Train/Test Split**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

print("Training set shape:", X_train.shape)
print("Test set shape:", X_test.shape)
print("\nTraining class distribution:")
print(y_train.value_counts())
print("\nTest class distribution:")
print(y_test.value_counts())

"""# **Apply SMOTE to Training Data**"""

from imblearn.over_sampling import SMOTE
from collections import Counter

print("Before SMOTE:", Counter(y_train))

smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print("After SMOTE:", Counter(y_train_smote))

"""# **Model Evaluation Function**"""

from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, confusion_matrix, classification_report

def evaluate_model(model, y_test, y_pred):
    # Accuracy
    acc = balanced_accuracy_score(y_test, y_pred)
    print("Test Balanced Accuracy:", acc)

    # Macro F1-score
    f1 = f1_score(y_test, y_pred, average="macro")
    print("Test Macro F1-score:", f1)

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

    plt.figure(figsize=(6,4))
    sns.heatmap(cm_percent, annot=True, fmt=".2f", cmap="Blues", xticklabels=model.classes_, yticklabels=model.classes_)
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    plt.show()

    # Detailed classification report
    print(classification_report(y_test, y_pred))

"""# **XGBoost Classifier**"""

import xgboost as xgb

# Baseline XGBoost model
xgb_base = xgb.XGBClassifier(
    objective='multi:softmax',        # CTG is multi-class (Normal, Suspect, Pathological)
    num_class=len(np.unique(y_train)),
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1
)

# Fit
xgb_base.fit(X_train_smote, y_train_smote)

# Predict
y_pred_xgb = xgb_base.predict(X_test)

evaluate_model(xgb_base, y_test, y_pred_xgb)

"""# **Explain General Model Behaviour**

## **Feature Importance Explanation Function**
"""

def show_feature_importance(model, importance_type):
    importance_dict = model.get_booster().get_score(importance_type=importance_type)

    # Convert to DataFrame for easier handling
    importance_df = pd.DataFrame(list(importance_dict.items()), columns=['Feature','Gain'])

    # Normalize the importance
    importance_df['Gain_norm'] = importance_df['Gain'] / importance_df['Gain'].sum()

    # Sort by normalized gain
    importance_df = importance_df.sort_values('Gain_norm', ascending=True)

    plt.figure(figsize=(8,6))
    bars = plt.barh(importance_df['Feature'], importance_df['Gain_norm'])
    plt.xlabel('Normalized Gain')
    plt.title('XGBoost Feature Importance (Normalized)')

    for bar in bars:
        width = bar.get_width()
        plt.text(width + 0.001, bar.get_y() + bar.get_height()/2, f'{width:.2f}', va='center')

    plt.show()

"""## **SHAP Display Function**"""

import shap

def show_shap(model):
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_test)

    for i in range(3):
        print()
        fig = plt.figure()
        plt.title(f"SHAP Summary ‚Äî Class {i} ({classes[i]})", fontsize=14, pad=15)
        shap.summary_plot(shap_values[..., i], X_test, feature_names=X_test.columns, show=False)
        plt.show()

"""## **Explain Model**"""

#Feature Importance
show_feature_importance(xgb_base, importance_type='gain')

#SHAP
show_shap(xgb_base)

"""# **Optimize XGBoost with SearchCV** (for macro-F1 score)"""

from sklearn.model_selection import RandomizedSearchCV

#Random Search Space
param_dist = {
    'n_estimators': [100, 200, 400],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [3, 5, 7, 9],
    'min_child_weight': [1, 3, 5],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0],
    'gamma': [0, 0.1, 0.3],
}

xgb_model = xgb.XGBClassifier(
    objective='multi:softmax',
    num_class=3,
    n_jobs=-1,
    random_state=42
)

random_xgb = RandomizedSearchCV(
    estimator=xgb_model,
    param_distributions=param_dist,
    n_iter=20,
    cv=5,
    scoring='f1_macro',
    n_jobs=-1,
    verbose=2,
    random_state=42
)

random_xgb.fit(X_train_smote, y_train_smote)

#Best Model
print("Best Parameters:")
print(random_xgb.best_params_)
print("\nBest Cross-Validation Macro F1-score: {:.4f}".format(random_xgb.best_score_))

best_xgb = random_xgb.best_estimator_

y_pred_best_xbg = best_xgb.predict(X_test)

evaluate_model(best_xgb, y_test, y_pred_best_xbg)

results_df = pd.DataFrame(random_xgb.cv_results_)
results_df_sorted = results_df.sort_values(by='mean_test_score', ascending=False)

print("\nüèÖ Top 10 Parameter Sets (by Macro F1):")
print(results_df_sorted[['mean_test_score', 'std_test_score', 'params']].head(10).to_string(index=False))

"""# **Optimize XGBoost with SearchCV** (for Balanced Accuracy score)"""

from sklearn.model_selection import RandomizedSearchCV

#Random Search Space
param_dist = {
    'n_estimators': [100, 200, 400],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [3, 5, 7, 9],
    'min_child_weight': [1, 3, 5],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0],
    'gamma': [0, 0.1, 0.3],
}

xgb_model = xgb.XGBClassifier(
    objective='multi:softmax',
    num_class=3,
    n_jobs=-1,
    random_state=42
)

random_xgb = RandomizedSearchCV(
    estimator=xgb_model,
    param_distributions=param_dist,
    n_iter=20,
    cv=5,
    scoring='balanced_accuracy',
    n_jobs=-1,
    verbose=2,
    random_state=42
)

random_xgb.fit(X_train_smote, y_train_smote)

#Best Model
print("Best Parameters:")
print(random_xgb.best_params_)
print("\nBest Cross-Validation Balanced Accuracy: {:.4f}".format(random_xgb.best_score_))

best_xgb = random_xgb.best_estimator_

y_pred_best_xbg = best_xgb.predict(X_test)

evaluate_model(best_xgb, y_test, y_pred_best_xbg)

results_df = pd.DataFrame(random_xgb.cv_results_)
results_df_sorted = results_df.sort_values(by='mean_test_score', ascending=False)

print("\nüèÖ Top 10 Parameter Sets (by Balanced Accuracy):")
print(results_df_sorted[['mean_test_score', 'std_test_score', 'params']].head(10).to_string(index=False))

"""# **Optimal Model**"""

import xgboost as xgb

# Optimized XGBoost model
xgb_opt = xgb.XGBClassifier(
    objective='multi:softmax',        # CTG is multi-class (Normal, Suspect, Pathological)
    num_class=len(np.unique(y_train)),
    n_estimators=400,
    max_depth=5,
    learning_rate=0.05,
    gamma=0.1,
    subsample=0.8,
    colsample_bytree=0.7,
    min_child_weight=1,
    random_state=42,
    n_jobs=-1
)

# Fit
xgb_opt.fit(X_train_smote, y_train_smote)

# Predict
y_pred_xgb_opt = xgb_opt.predict(X_test)

evaluate_model(xgb_opt, y_test, y_pred_xgb_opt)

"""# **Explain Fined-Tuned Model Behaviour**"""

show_feature_importance(xgb_opt, importance_type='gain')

show_shap(xgb_opt)

xgb_base.save_model("xgb_base.json")
xgb_opt.save_model("xgb_opt.json")